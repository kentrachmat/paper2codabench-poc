{
  "raw_response": "{\n  \"@context\": {\n    \"@vocab\": \"http://schema.org/\",\n    \"cr\": \"http://mlcommons.org/croissant/\",\n    \"sc\": \"http://schema.org/\"\n  },\n  \"@type\": \"cr:TaskProblem\",\n  \"@id\": \"erasing-invisible-task\",\n  \"name\": \"Erasing the Invisible\",\n  \"description\": \"Evaluate robustness of invisible watermarks embedded in AI-generated images against adversarial attacks. Participants aim to remove or degrade watermarks while preserving image quality.\",\n  \"paper_id\": \"erasing-invisible-paper\",\n  \"cr:input\": [\n    {\n      \"name\": \"competition_dataset\",\n      \"description\": \"Dataset consists of 600 PNG images divided equally between two tracks: Beige-box (Gaussian Shading, StegaStamp) and Black-box (JigMark, PRC, StableSignature, Trufo, and combinations like Gaussian Shading + JigMark). Metadata includes image_index and watermarked_image.\",\n      \"url\": \"https://huggingface.co/datasets/furonghuang-lab/ETI_Competition_Data\"\n    }\n  ],\n  \"cr:output\": {\n    \"name\": \"attacked_images\",\n    \"description\": \"Modified PNG images minimizing watermark detection while preserving visual quality. Output includes 300 images per submission.\",\n    \"cr:schema\": {\n      \"name\": \"output_schema\",\n      \"field\": [\n        {\"name\": \"image_index\", \"dataType\": \"sc:Text\", \"description\": \"Unique identifier for each image, e.g., image_001.\"},\n        {\"name\": \"attacked_image\", \"dataType\": \"sc:URL\", \"description\": \"URL or file path to the modified PNG image.\"}\n      ]\n    }\n  },\n  \"cr:implementation\": {\n    \"cr:environment\": {\n      \"language\": \"Python\",\n      \"packages\": [\"PyTorch\", \"ONNXRuntime-GPU\", \"Transformers\", \"Diffusers\"]\n    },\n    \"entryPoint\": \"solution.py\",\n    \"interface\": \"attack(input_dir, output_dir)\"\n  },\n  \"cr:evaluation\": {\n    \"primaryMetric\": \"final_score\",\n    \"metrics\": [\"final_score\", \"watermark_removal_metric\", \"image_quality_metric\"],\n    \"higherIsBetter\": false,\n    \"notes\": \"Final score is computed as Euclidean distance in Q-A space: sqrt(Q\u00b2 + A\u00b2). Lower scores indicate better performance. Q aggregates eight IQMs normalized to [0.1, 0.9], and A is derived from TPR@0.1%FPR.\"\n  },\n  \"cr:execution\": {\n    \"runtimeLimitSec\": 2400,\n    \"memoryLimitMb\": 8192,\n    \"allowedExternalData\": \"unknown\"\n  },\n  \"open_questions\": [\n    \"Exact Docker image used for evaluation is unclear. Paper mentions 'johnding1996/codabench-erasinginvisible:latest', but further verification is needed.\",\n    \"Allowed external data usage is unspecified. Are participants permitted to use pre-trained models beyond those mentioned?\"\n  ],\n  \"fill_in_the_blank\": [\n    \"cr:execution.allowedExternalData - external data usage policy not specified in paper\"\n  ]\n}"
}