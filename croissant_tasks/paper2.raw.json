{
  "raw_response": "{\n  \"@context\": {\n    \"@vocab\": \"http://schema.org/\",\n    \"cr\": \"http://mlcommons.org/croissant/\",\n    \"sc\": \"http://schema.org/\"\n  },\n  \"@type\": \"cr:TaskProblem\",\n  \"@id\": \"neurips2024-llm-privacy-challenge\",\n  \"name\": \"NeurIPS 2024 LLM Privacy Challenge\",\n  \"description\": \"Address privacy risks in large language models (LLMs) through attacking privacy vulnerabilities (Red Team) or defending against privacy attacks (Blue Team).\",\n  \"paper_id\": \"neurips2024-llm-privacy-challenge\",\n  \"cr:input\": [\n    {\n      \"name\": \"competition_dataset\",\n      \"description\": \"Synthetic datasets inspired by real-world private datasets, such as Enron emails, with sensitive fields replaced by random strings. Example: Original data: 'John Doe, johndoe@example.com'; Synthetic version: 'RandomName123, randomemail456@example.com'. Includes training, validation, and test splits.\",\n      \"url\": \"[FILL IN THE BLANK]\"\n    }\n  ],\n  \"cr:output\": {\n    \"name\": \"predictions\",\n    \"description\": \"Outputs depend on the track: Red Team outputs extracted sensitive information (e.g., names, email addresses); Blue Team outputs enhanced LLMs or defense methods evaluated for privacy protection and utility.\",\n    \"cr:schema\": {\n      \"name\": \"prediction_schema\",\n      \"field\": [\n        {\"name\": \"id\", \"dataType\": \"sc:Text\", \"description\": \"Unique identifier for the sample, e.g., 'sample_001'\"},\n        {\"name\": \"output\", \"dataType\": \"sc:Text\", \"description\": \"Red Team: Extracted sensitive information (e.g., 'John Doe, johndoe@example.com'). Blue Team: Defense method or enhanced LLM description.\"}\n      ]\n    }\n  },\n  \"cr:implementation\": {\n    \"cr:environment\": {\n      \"language\": \"Python\",\n      \"packages\": [\"torch\", \"transformers\", \"numpy\", \"pandas\"]\n    },\n    \"entryPoint\": \"solution.py\",\n    \"interface\": \"predict(input_dir, output_dir)\"\n  },\n  \"cr:evaluation\": {\n    \"primaryMetric\": \"attack_accuracy\",\n    \"metrics\": [\"attack_accuracy\", \"defense_effectiveness\", \"efficiency\", \"model_effectiveness\"],\n    \"higherIsBetter\": true,\n    \"notes\": \"Attack accuracy measures success rate of extracting sensitive information (Red Team). Defense effectiveness measures reduction in attack accuracy (Blue Team). Efficiency evaluates computational overhead. Model effectiveness assesses LLM utility post-defense.\"\n  },\n  \"cr:execution\": {\n    \"runtimeLimitSec\": \"[FILL IN THE BLANK]\",\n    \"memoryLimitMb\": \"[FILL IN THE BLANK]\",\n    \"allowedExternalData\": \"unknown\"\n  },\n  \"open_questions\": [\n    \"What are the exact runtime and memory limits for submissions?\",\n    \"What are the specific dataset URLs for downloading the synthetic datasets?\",\n    \"What are the exact software versions required for the standardized environment?\"\n  ],\n  \"fill_in_the_blank\": [\n    \"cr:input[0].url - dataset URL not specified in paper\",\n    \"cr:execution.runtimeLimitSec - runtime limit not specified in paper\",\n    \"cr:execution.memoryLimitMb - memory limit not specified in paper\"\n  ]\n}"
}